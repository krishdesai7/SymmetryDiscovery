{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "        import numpy as np\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.metrics import roc_curve, auc,roc_auc_score\n",
    "        from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, ReLU, ELU, PReLU, Input, Concatenate, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myloss2d(y_true, y_pred, alpha = 0.0):\n",
    "    #alpha determines the amount of decorrelation; 0 means no decorrelation.\n",
    "    \n",
    "    #We want to learn f(g(x)) = x with g != identity and g(x) and x should have the same probability density.\n",
    "    #g(x) = y_pred[:,0]\n",
    "    #f(g(x)) = y_pred[:,1]\n",
    "    #h(x) = y_pred[:,2]\n",
    "    #h(g(x)) = y_pred[:,3]\n",
    "    \n",
    "    myoutput =  mse(y_true[:,0],y_pred[:,1]) \\\n",
    "                - alpha*binary_crossentropy(y_pred[:,2],K.ones_like(y_pred[:,2])) \\\n",
    "                - alpha*binary_crossentropy(y_pred[:,3],0.*K.ones_like(y_pred[:,2]))\n",
    "    return myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on j= 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'around' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-4d236330cd01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mslopes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mintercepts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'around' is not defined"
     ]
    }
   ],
   "source": [
    "num_iters = 10\n",
    "training = 20\n",
    "zero = [0]*100000\n",
    "slopes = []\n",
    "intercepts = []\n",
    "\n",
    "for j in range(num_iters):\n",
    "    print(\"on j=\",j)\n",
    "    x0 = np.random.normal(0,1,100000)\n",
    "    x1 = np.random.normal(0,2,100000)\n",
    "    X = np.concatenate((np.c_[x0, zero], np.c_[zero, x1]))\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    myinput_2d = Input(shape=(2,))\n",
    "    encoded_2d = Dense(5, activation='elu')(myinput_2d)\n",
    "    encoded_2d = Dense(5, activation='elu')(encoded_2d)\n",
    "    encoded_2d = Dense(2, activation='linear')(encoded_2d)\n",
    "\n",
    "    encoder_2d = Model(myinput_2d, encoded_2d)\n",
    "    encoder2_2d = encoder_2d(encoder_2d(myinput_2d))\n",
    "    autoencoder_2d = Model(myinput_2d, encoder2_2d)\n",
    "\n",
    "    combinedModel_2d = Model(myinput_2d,Concatenate(axis=-1)([encoded_2d, encoder2_2d]))\n",
    "\n",
    "    myinput_classify_2d = Input(shape=(2,))\n",
    "    myclassifier_2d = Dense(128, activation='elu')(myinput_classify_2d)\n",
    "    myclassifier_2d = Dense(64, activation='elu')(myclassifier_2d)\n",
    "    myclassifier_2d = Dense(1, activation='sigmoid')(myclassifier_2d)\n",
    "    myclassifier_model_2d = Model(myinput_classify_2d, myclassifier_2d)\n",
    "    myclassifier_input_2d = myclassifier_model_2d(myinput_2d)\n",
    "    myclassifier_encoded_2d = myclassifier_model_2d(encoded_2d)\n",
    "\n",
    "    combinedModel_classifier_2d = Model(myinput_2d,Concatenate(axis=-1)([encoded_2d, encoder2_2d, myclassifier_input_2d, myclassifier_encoded_2d]))\n",
    "\n",
    "    preds = []\n",
    "    preds += [encoder_2d.predict(X)]\n",
    "\n",
    "    for i in range(training):\n",
    "        #Now, train the classifier\n",
    "        encoded_x_2d = encoder_2d.predict(X)\n",
    "        myclassifier_model_2d.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "        myclassifier_model_2d.fit(np.concatenate([X,encoded_x_2d]),np.concatenate([np.ones(len(X)),np.zeros(len(X))]), epochs=1, batch_size=int(0.01*len(X)), verbose=0)\n",
    "\n",
    "        #Now, update the autoencoder\n",
    "        for layer in myclassifier_model_2d.layers[:]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        combinedModel_classifier_2d.compile(optimizer='adam', loss=lambda y_true, y_pred: myloss2d(y_true, y_pred))\n",
    "        combinedModel_classifier_2d.fit(X,X, epochs=1, batch_size=int(0.01*len(X)), verbose=0)\n",
    "\n",
    "        autoencoder_2d.compile(optimizer='adam', loss='mse')\n",
    "        autoencoder_2d.fit(X,X, epochs=5, batch_size=int(0.01*len(x0)), verbose=0)\n",
    "\n",
    "        preds += [encoder_2d.predict(X)]\n",
    "\n",
    "        for layer in myclassifier_model_2d.layers[:]:\n",
    "            layer.trainable = True\n",
    "            \n",
    "            \n",
    "            \n",
    "    model = LinearRegression().fit(X, preds[-1]);\n",
    "    slopes.append(model.coef_);\n",
    "    intercepts.append(model.intercept_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n",
      "1.0\n",
      "-1.0\n",
      "-1.0\n",
      "1.0\n",
      "1.0\n",
      "-1.0\n",
      "-1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_iters):\n",
    "    det = np.linalg.det(slopes[i])\n",
    "    print(round(det, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slopes:\n",
      "-0.09278478527234023\t0.9843554811580026 \n",
      "0.9992958749017833  \t0.09981565741990134\n",
      "\n",
      "\n",
      "0.996219824011967     \t-7.252000201800778e-05\n",
      "-0.0010184638323343194\t0.9981393463719728    \n",
      "\n",
      "\n",
      "0.9937786860825532    \t0.0018701124955965381\n",
      "-0.0018036101566574131\t0.9959162301705138   \n",
      "\n",
      "\n",
      "0.12135622184597479\t0.7255222110337151  \n",
      "1.3774880135779222 \t-0.10862585202451683\n",
      "\n",
      "\n",
      "0.6157793517012241\t0.4740765417630849 \n",
      "1.2395782399295983\t-0.6028152808746761\n",
      "\n",
      "\n",
      "0.9993351296475016   \t0.001222516721229062\n",
      "0.0022885791141539426\t0.9988599081316957  \n",
      "\n",
      "\n",
      "-0.988037076305449 \t0.012396866506691495\n",
      "0.11694926594647093\t-0.9905298537731809 \n",
      "\n",
      "\n",
      "0.06425309650154268\t0.9525106710159424   \n",
      "1.0270718908730325 \t-0.027679601969283495\n",
      "\n",
      "\n",
      "0.7667731650052971\t0.35158197525753526\n",
      "1.4697452952259606\t-0.6577105911310936\n",
      "\n",
      "\n",
      "0.9967595756908981    \t0.0011562549183422365\n",
      "-0.0037155190499997457\t0.9968674134796016   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Slopes:\")\n",
    "for i in range(num_iters):\n",
    "    s = [[str(e) for e in row] for row in slopes[i]]\n",
    "    lens = [max(map(len, col)) for col in zip(*s)]\n",
    "    fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "    table = [fmt.format(*row) for row in s]\n",
    "    print (\"\\n\".join(table))\n",
    "    print(\"\\n\")\n",
    "    \n",
    "print(\"Intercepts:\")\n",
    "for i in range(num_iters):\n",
    "    s = [[str(e) for e in row] for row in intercepts[i]]\n",
    "    lens = [max(map(len, col)) for col in zip(*s)]\n",
    "    fmt = '\\t'.join('{{:{}}}'.format(x) for x in lens)\n",
    "    table = [fmt.format(*row) for row in s]\n",
    "    print (\"\\n\".join(table))\n",
    "    print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-cpu",
   "language": "python",
   "name": "tensorflow_intel_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
