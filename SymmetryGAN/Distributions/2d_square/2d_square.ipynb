{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3be8f84-d681-4bc9-bd5f-06e28b5df37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0\n",
      "epoch =  1999\n",
      "epoch =  3999\n",
      "epoch =  5999\n",
      "epoch =  7999\n",
      "epoch =  9999\n",
      "c_i =  [0.98823977]\n",
      "s_i =  [-0.96480036]\n",
      "c_f =  [1.0044719]\n",
      "s_f =  [-0.019113036]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from matplotlib import gridspec\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, kernel_initilizer=tf.keras.initializers.RandomUniform(minval=-1., maxval=1.), **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "        self.kernel_initializer = tf.keras.initializers.get(kernel_initilizer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._c = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=self.kernel_initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._s = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=self.kernel_initializer, #'uniform',\n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        npc = [[self._c,-1.0*self._s],[self._s,self._c]]\n",
    "        M = tf.convert_to_tensor(npc)\n",
    "        M = tf.reshape(M, [2, 2])\n",
    "        return tf.linalg.matmul(X, M)\n",
    "    \n",
    "#Quick vanilla GAN from https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=2):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))    \n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(n_outputs=1):\n",
    "\t#model = Sequential()\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))    \n",
    "\t#model.add(Dense(n_outputs, activation='linear'))\n",
    "\n",
    "\tmymodel_inputtest = Input(shape=(2,))\n",
    "\tmymodel_test = MyLayer()(mymodel_inputtest)\n",
    "\tmodel = Model(mymodel_inputtest, mymodel_test)\n",
    "\treturn model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\tamounts = np.random.multinomial(n,np.ones(25)/25.) \n",
    "\tX1 = []\n",
    "\tX2 = []\n",
    "\tmycounter = 0\n",
    "\tfor i in range(5):\n",
    "\t\tfor j in range(5):\n",
    "\t\t\tX1 = np.concatenate([X1,np.random.normal(i+0.1,0.1,amounts[mycounter])])\n",
    "\t\t\tX2 = np.concatenate([X2,np.random.normal(j+0.1,0.1,amounts[mycounter])])\n",
    "\t\t\tmycounter+=1\n",
    "\t\t\tpass\n",
    "\t\tpass    \n",
    "    \n",
    "\tX1 = X1.reshape(len(X1), 1)\n",
    "\tX2 = X2.reshape(len(X2), 1)    \n",
    "\tX = hstack((X1, X2))\n",
    "\tnp.random.shuffle(X)\n",
    "\t# generate class labels\n",
    "\ty = ones((n, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = generate_real_samples(n)\n",
    "\treturn x_input[0]\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples_with_input(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y, x_input\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "\t# determine half the size of one batch, for updating the discriminator\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# prepare real samples\n",
    "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
    "\t\t# prepare fake examples\n",
    "\t\tx_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "\t\t# update discriminator\n",
    "\t\td_model.train_on_batch(x_real, y_real)\n",
    "\t\td_model.train_on_batch(x_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tx_gan = generate_latent_points(n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
    "\t\tif (i+1) % n_eval == 0:\n",
    "\t\t\tprint(\"epoch = \", i)\n",
    "          \n",
    "        \n",
    "N = 1\n",
    "c_i = []\n",
    "s_i = []\n",
    "c_f = []\n",
    "s_f = []\n",
    "for j in range(N):\n",
    "    print(\"j = \", j)\n",
    "    # create the discriminator\n",
    "    discriminator = define_discriminator()\n",
    "    # create the generator\n",
    "    generator = define_generator()\n",
    "    # create the gan\n",
    "    gan_model = define_gan(generator, discriminator)\n",
    "    c_i.append(generator.layers[-1].get_weights()[0][0])\n",
    "    s_i.append(generator.layers[-1].get_weights()[1][0])\n",
    "    # train model\n",
    "    train(generator, discriminator, gan_model)\n",
    "    c_f.append(generator.layers[-1].get_weights()[0][0])\n",
    "    s_f.append(generator.layers[-1].get_weights()[1][0])\n",
    "    print(\"c_i = \", c_i)\n",
    "    print(\"s_i = \", s_i)\n",
    "    print(\"c_f = \", c_f)\n",
    "    print(\"s_f = \", s_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8700f075-0953-4673-a25e-997176fcb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm, ticker\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2fe6b9-2dd8-4e08-b82f-62bb91ef6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p(x,mu,sigma):\n",
    "    return sp.multivariate_normal.pdf(x, mean=mu, cov=sigma)\n",
    "\n",
    "def g(n, c, s, x):\n",
    "    r = np.array([[c, s], [-s, c]])\n",
    "    return np.matmul(x, np.linalg.matrix_power(r, n))\n",
    "\n",
    "mu = np.array([0, 0])\n",
    "sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "def h(c, s, x):\n",
    "    r = np.array([[c, s], [-s, c]])\n",
    "    p0 = p(x, mu, sigma)\n",
    "    p1 = p(x, np.matmul(mu, r), np.matmul(np.transpose(r), np.matmul(sigma, r)))\n",
    "    return p0/(p0 + p1)\n",
    "    #return p(x,0.5,1)/(p(x,0.5,1) + abs(c)*p(a+c*x,0.5,1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
