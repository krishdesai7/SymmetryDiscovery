{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import hstack\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Lambda, Dense, Input, Layer, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from matplotlib import gridspec\n",
    "from tensorflow.keras.layers import Layer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLayer(Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self._c = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=-1., maxval=1.), #'uniform',\n",
    "                                    trainable=True)\n",
    "        self._s = self.add_weight(name='x', \n",
    "                                    shape=(1,),\n",
    "                                    initializer=tf.keras.initializers.RandomUniform(minval=-1., maxval=1.), #'uniform',\n",
    "                                    trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, X):\n",
    "        npc = [[self._c,-1.0*self._s],[self._s,self._c]]\n",
    "        M = tf.convert_to_tensor(npc)\n",
    "        M = tf.reshape(M, [2, 2])\n",
    "        #print(\"SHAPE OF THINGS:\", tf.shape(self._c), \"*****\", tf.shape(self._s), \"*****\", tf.shape(M), \"****\", tf.shape(X) )\n",
    "        #print(\"M:\", M)\n",
    "        return tf.linalg.matmul(X, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick vanilla GAN from https://machinelearningmastery.com/how-to-develop-a-generative-adversarial-network-for-a-1-dimensional-function-from-scratch-in-keras/\n",
    " \n",
    "# define the standalone discriminator model\n",
    "def define_discriminator(n_inputs=2):\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))\n",
    "\tmodel.add(Dense(25, activation='relu', input_dim=n_inputs))    \n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# define the standalone generator model\n",
    "def define_generator(n_outputs=1):\n",
    "\t#model = Sequential()\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))\n",
    "\t#model.add(Dense(15, activation='relu', input_dim=n_outputs))    \n",
    "\t#model.add(Dense(n_outputs, activation='linear'))\n",
    "\n",
    "\tmymodel_inputtest = Input(shape=(2,))\n",
    "\tmymodel_test = MyLayer()(mymodel_inputtest)\n",
    "\tmodel = Model(mymodel_inputtest, mymodel_test)\n",
    "\treturn model\n",
    " \n",
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tdiscriminator.trainable = False\n",
    "\t# connect them\n",
    "\tmodel = Sequential()\n",
    "\t# add generator\n",
    "\tmodel.add(generator)\n",
    "\t# add the discriminator\n",
    "\tmodel.add(discriminator)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\treturn model\n",
    " \n",
    "# generate n real samples with class labels\n",
    "def generate_real_samples(n):\n",
    "\tX = np.random.multivariate_normal([0, 0], [[1, 0],[0, 1]],n)\n",
    "\ty = ones((n, 1))\n",
    "\treturn X, y\n",
    " \n",
    "# generate points in latent space as input for the generator\n",
    "def generate_latent_points(n):\n",
    "\t# generate points in the latent space\n",
    "\tx_input = generate_real_samples(n)\n",
    "\treturn x_input[0]\n",
    " \n",
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y\n",
    "\n",
    "def generate_fake_samples_with_input(generator, n):\n",
    "\t# generate points in latent space\n",
    "\tx_input = generate_latent_points(n)\n",
    "\t# predict outputs\n",
    "\tX = generator.predict(x_input)\n",
    "\t# create class labels\n",
    "\ty = zeros((n, 1))\n",
    "\treturn X, y, x_input\n",
    " \n",
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "\t# determine half the size of one batch, for updating the discriminator\n",
    "\thalf_batch = int(n_batch / 2)\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_epochs):\n",
    "\t\t# prepare real samples\n",
    "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
    "\t\t# prepare fake examples\n",
    "\t\tx_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "\t\t# update discriminator\n",
    "\t\td_model.train_on_batch(x_real, y_real)\n",
    "\t\td_model.train_on_batch(x_fake, y_fake)\n",
    "\t\t# prepare points in latent space as input for the generator\n",
    "\t\tx_gan = generate_latent_points(n_batch)\n",
    "\t\t# create inverted labels for the fake samples\n",
    "\t\ty_gan = ones((n_batch, 1))\n",
    "\t\t# update the generator via the discriminator's error\n",
    "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
    "\t\tif (i+1) % n_eval == 0:\n",
    "\t\t\tprint(\"epoch = \", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "j =  0\n",
      "epoch =  1999\n",
      "epoch =  3999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-178db53b4d05>\", line 17, in <module>\n",
      "    train(generator, discriminator, gan_model)\n",
      "  File \"<ipython-input-3-7205c27fdef9>\", line 79, in train\n",
      "    x_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
      "  File \"<ipython-input-3-7205c27fdef9>\", line 56, in generate_fake_samples\n",
      "    X = generator.predict(x_input)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 88, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1249, in predict\n",
      "    model=self)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1112, in __init__\n",
      "    model=model)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 362, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1652, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4071, in __init__\n",
      "    map_func, self._transformation_name(), dataset=input_dataset)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3221, in __init__\n",
      "    self._function = wrapper_fn.get_concrete_function()\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2532, in get_concrete_function\n",
      "    *args, **kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2496, in _get_concrete_function_garbage_collected\n",
      "    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2777, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2667, in _create_graph_function\n",
      "    capture_by_value=self._capture_by_value),\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 981, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3214, in wrapper_fn\n",
      "    ret = _wrapper_helper(*args)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 3156, in _wrapper_helper\n",
      "    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 262, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 492, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 346, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 351, in slice_batch_indices\n",
      "    flat_dataset = dataset_ops.DatasetV2.from_tensor_slices(first_k_indices)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 640, in from_tensor_slices\n",
      "    return TensorSliceDataset(tensors)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2858, in __init__\n",
      "    element = structure.normalize_element(element)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/data/util/structure.py\", line 88, in normalize_element\n",
      "    with ops.name_scope(\"normalize_element\"):\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6217, in name_scope\n",
      "    return internal_name_scope_v1(name, default_name, values)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 6243, in __init__\n",
      "    def __init__(self, name, default_name=None, values=None):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/inspect.py\", line 1464, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/linecache.py\", line 136, in updatecache\n",
      "    with tokenize.open(fullname) as fp:\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/tokenize.py\", line 449, in open\n",
      "    encoding, lines = detect_encoding(buffer.readline)\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/tokenize.py\", line 418, in detect_encoding\n",
      "    first = read_or_stop()\n",
      "  File \"/usr/common/software/tensorflow/gpu-tensorflow/2.2.0-py37/lib/python3.7/tokenize.py\", line 376, in read_or_stop\n",
      "    return readline()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "N = 2\n",
    "c_i = []\n",
    "s_i = []\n",
    "c_f = []\n",
    "s_f = []\n",
    "for j in range(N):\n",
    "    print(\"j = \", j)\n",
    "    # create the discriminator\n",
    "    discriminator = define_discriminator()\n",
    "    # create the generator\n",
    "    generator = define_generator()\n",
    "    # create the gan\n",
    "    gan_model = define_gan(generator, discriminator)\n",
    "    c_i.append(generator.layers[-1].get_weights()[0][0])\n",
    "    s_i.append(generator.layers[-1].get_weights()[1][0])\n",
    "    # train model\n",
    "    train(generator, discriminator, gan_model)\n",
    "    c_f.append(generator.layers[-1].get_weights()[0][0])\n",
    "    s_f.append(generator.layers[-1].get_weights()[1][0])\n",
    "    with open('fO(2)data.txt', 'w') as f:\n",
    "        print(\"c_i = \", c_i, file=f)\n",
    "        print(\"s_i = \", s_i, file=f)\n",
    "        print(\"c_f = \", c_f, file=f)\n",
    "        print(\"s_f = \", s_f, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npc = np.array([[1, 2],[3, 4]])\n",
    "M = tf.convert_to_tensor(npc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([2, 2], dtype=int32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5668086]\n",
      "[0.70566803]\n"
     ]
    }
   ],
   "source": [
    "print(np.arccos(c_f))\n",
    "print(np.arcsin(s_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.132300124776524]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det = [c_f[n]**2 + s_f[n]**2 for n in range(N)]\n",
    "det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-v2.2.0-gpu",
   "language": "python",
   "name": "tensorflow_gpu_2.2.0-py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
